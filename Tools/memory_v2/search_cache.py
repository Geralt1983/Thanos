"""
Search Result Caching for Memory V2.

Provides TTL-based LRU caching for full memory search results to reduce redundant
database queries, heat ranking calculations, and result processing during repeated
searches within a conversation.

Key Features:
    - TTL-based expiration (default 5 minutes)
    - Thread-safe in-memory cache backend
    - Content-based cache keys using SHA-256 hashing
    - Automatic expiration checking on access
    - Manual cleanup of expired entries

Key Classes:
    SearchResultCache: Manages cached search results with TTL support

Usage:
    from Tools.memory_v2.search_cache import SearchResultCache

    # Initialize cache
    cache = SearchResultCache(ttl_seconds=300)

    # Generate cache key
    key = cache.generate_key(
        query="Orlando project status",
        limit=5,
        filters={"client": "Orlando"}
    )

    # Check for cached results
    cached_results = cache.get(key)
    if cached_results:
        return cached_results

    # Cache new results
    results = [...perform search...]
    cache.set(key, results)

    # Cleanup expired entries
    cache.clear_expired()

Cache Key Generation:
    Cache keys are generated by hashing a combination of:
    - Query text
    - Result limit
    - All filter parameters (client, project, domain, source, entities)

    This ensures that identical search requests return cached results while
    different parameters create separate cache entries.

TTL and Expiration:
    - Results are cached for the configured TTL period (default 300s)
    - Expired entries are automatically removed on access via get()
    - Manual cleanup can be triggered with clear_expired()

Integration:
    The SearchResultCache is automatically used by MemoryService.search()
    for all search operations. This transparent caching eliminates redundant
    work for repeated queries during a conversation.
"""

import hashlib
import json
import logging
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from threading import Lock
from typing import Any, Optional

logger = logging.getLogger(__name__)


@dataclass
class CacheEntry:
    """
    A single cache entry with metadata.

    Tracks the cached value, expiration time, and access patterns.
    """

    key: str
    """Cache key"""

    value: Any
    """Cached value"""

    created_at: datetime = field(default_factory=datetime.now)
    """When entry was created"""

    expires_at: Optional[datetime] = None
    """When entry expires (None = never)"""

    access_count: int = 0
    """Number of times entry has been accessed"""

    last_accessed: Optional[datetime] = None
    """When entry was last accessed"""

    def is_expired(self) -> bool:
        """
        Check if cache entry has expired.

        Returns:
            True if entry is expired, False otherwise
        """
        if self.expires_at is None:
            return False
        return datetime.now() >= self.expires_at

    def touch(self) -> None:
        """Update access metadata when entry is accessed."""
        self.access_count += 1
        self.last_accessed = datetime.now()


class MemoryCacheBackend:
    """
    In-memory cache backend using a dictionary.

    Thread-safe implementation for storing cache entries.
    """

    def __init__(self):
        """Initialize memory cache backend."""
        self._cache: dict[str, CacheEntry] = {}
        self._lock = Lock()

    def get(self, key: str) -> Optional[CacheEntry]:
        """
        Get cache entry by key.

        Automatically removes expired entries.

        Args:
            key: Cache key

        Returns:
            Cache entry if found and not expired, None otherwise
        """
        with self._lock:
            entry = self._cache.get(key)
            if entry and entry.is_expired():
                del self._cache[key]
                return None
            return entry

    def set(self, key: str, entry: CacheEntry) -> None:
        """
        Store cache entry.

        Args:
            key: Cache key
            entry: Cache entry to store
        """
        with self._lock:
            self._cache[key] = entry

    def delete(self, key: str) -> bool:
        """
        Delete cache entry.

        Args:
            key: Cache key

        Returns:
            True if entry was deleted, False if not found
        """
        with self._lock:
            if key in self._cache:
                del self._cache[key]
                return True
            return False

    def clear(self) -> None:
        """Clear all cache entries."""
        with self._lock:
            self._cache.clear()

    def size(self) -> int:
        """
        Get current cache size.

        Returns:
            Number of entries in cache
        """
        with self._lock:
            return len(self._cache)

    def keys(self) -> list[str]:
        """
        Get all cache keys.

        Returns:
            List of cache keys
        """
        with self._lock:
            return list(self._cache.keys())


class SearchResultCache:
    """
    TTL-based cache for memory search results.

    Provides caching with automatic expiration and thread-safe access.
    """

    def __init__(self, ttl_seconds: int = 300):
        """
        Initialize search result cache.

        Args:
            ttl_seconds: Time-to-live for cache entries in seconds (default 300 = 5 minutes)
        """
        self.ttl_seconds = ttl_seconds
        self._backend = MemoryCacheBackend()
        self._lock = Lock()

        logger.info(
            f"Initialized SearchResultCache with ttl={self.ttl_seconds}s"
        )

    def generate_key(
        self,
        query: str,
        limit: int = 10,
        client: Optional[str] = None,
        project: Optional[str] = None,
        domain: Optional[str] = None,
        source: Optional[str] = None,
        entities: Optional[list[str]] = None,
        filters: Optional[dict[str, Any]] = None,
    ) -> str:
        """
        Generate cache key from search parameters.

        Creates a deterministic cache key by hashing all search parameters.

        Args:
            query: Search query text
            limit: Maximum number of results
            client: Optional client filter
            project: Optional project filter
            domain: Optional domain filter
            source: Optional source filter
            entities: Optional entities filter
            filters: Optional additional filters

        Returns:
            Cache key string
        """
        # Build key components dict
        key_components = {
            "query": query,
            "limit": limit,
        }

        # Add optional filters
        if client:
            key_components["client"] = client
        if project:
            key_components["project"] = project
        if domain:
            key_components["domain"] = domain
        if source:
            key_components["source"] = source
        if entities:
            key_components["entities"] = sorted(entities)  # Sort for deterministic hashing
        if filters:
            key_components["filters"] = filters

        # Create deterministic JSON representation
        key_str = json.dumps(key_components, sort_keys=True)

        # Hash for compact key
        key_hash = hashlib.sha256(key_str.encode()).hexdigest()

        return f"search:{key_hash[:16]}"

    def get(self, key: str) -> Optional[Any]:
        """
        Get cached search results.

        Args:
            key: Cache key

        Returns:
            Cached results if found and valid, None otherwise
        """
        try:
            entry = self._backend.get(key)

            if entry is None:
                logger.debug(f"Cache miss for {key}")
                return None

            # Update access metadata
            entry.touch()
            self._backend.set(key, entry)

            age_seconds = (datetime.now() - entry.created_at).total_seconds()
            logger.debug(
                f"Cache hit for {key} (age: {age_seconds:.1f}s, access_count: {entry.access_count})"
            )
            return entry.value

        except Exception as e:
            logger.error(f"Cache get error for {key}: {e}")
            return None

    def set(self, key: str, results: Any) -> None:
        """
        Cache search results.

        Args:
            key: Cache key
            results: Search results to cache
        """
        try:
            # Calculate expiration
            expires_at = datetime.now() + timedelta(seconds=self.ttl_seconds)

            # Create entry
            entry = CacheEntry(
                key=key,
                value=results,
                expires_at=expires_at,
            )

            # Store entry
            self._backend.set(key, entry)

            logger.debug(
                f"Cached search results for {key} (ttl: {self.ttl_seconds}s)"
            )

        except Exception as e:
            logger.error(f"Cache set error for {key}: {e}")

    def delete(self, key: str) -> bool:
        """
        Delete cached results.

        Args:
            key: Cache key

        Returns:
            True if entry was deleted, False if not found
        """
        try:
            deleted = self._backend.delete(key)
            if deleted:
                logger.debug(f"Deleted cache entry {key}")
            return deleted
        except Exception as e:
            logger.error(f"Cache delete error for {key}: {e}")
            return False

    def clear(self) -> None:
        """Clear all cache entries."""
        try:
            self._backend.clear()
            logger.info("Cache cleared")
        except Exception as e:
            logger.error(f"Cache clear error: {e}")

    def clear_expired(self) -> int:
        """
        Remove all expired entries from cache.

        Returns:
            Number of entries removed
        """
        removed = 0
        try:
            for key in self._backend.keys():
                entry = self._backend.get(key)
                # Note: get() already removes expired entries, so this will
                # only count entries that expired since the last access
                if entry is None:
                    # Entry was expired and removed by get()
                    removed += 1

            if removed > 0:
                logger.info(f"Removed {removed} expired cache entries")

        except Exception as e:
            logger.error(f"Error clearing expired entries: {e}")

        return removed

    def size(self) -> int:
        """
        Get current cache size.

        Returns:
            Number of entries in cache
        """
        return self._backend.size()
